trainer:
  accelerator: 'gpu'
  num_nodes: 5
  devices: 8
  min_steps: 3000000
  max_steps: 3000000
  precision: 16-mixed
  limit_val_batches: 2560
  val_check_interval: 4000
  num_sanity_val_steps: 0
  accumulate_grad_batches:  1

# loss
lambdas:
  lambda_disc: 1.0
  lambda_feat_match_loss: 1.0
  lambda_mel_loss: 15.0
  lambda_adv: 1.0
  lambda_stft_loss: 1.0
  lambda_semantic_loss: 5
  lambda_perceptual_loss: 0
use_mel_loss: true
use_feat_match_loss: true
use_stft_loss: false

stft_loss_params:
  fft_sizes: [512,2048]
  hop_sizes: [128,512]
  win_lengths: [512,2048]
  window: hann_window

# optimizer
gen_optim_params:
  lr: 1.0
  betas: [0.8, 0.9]
disc_optim_params:
  lr: 1.0
  betas: [0.8, 0.9]
gen_grad_clip: 1.0
disc_grad_clip: 1.0

# scheduler
gen_schedule_params:
  warmup_step: 3000
  down_step: 400000
  min_lr: 2.0e-5 # this should be the final lr
  max_lr: 1.0e-4 
disc_schedule_params:
  warmup_step: 3000
  down_step: 400000
  min_lr: 2.0e-5 # this should be the final lr
  max_lr: 1.0e-4 
